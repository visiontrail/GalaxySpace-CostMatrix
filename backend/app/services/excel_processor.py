"""
Excel æ•°æ®å¤„ç†æœåŠ¡
è´Ÿè´£è¯»å–ã€åˆ†æã€å¤„ç† Excel æ–‡ä»¶
"""
import pandas as pd
import numpy as np
from openpyxl import load_workbook
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
import re
import os
import time
from collections import Counter

from app.utils.logger import get_logger


class ExcelProcessor:
    """Excel å¤„ç†å™¨"""
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.sheets_data: Dict[str, pd.DataFrame] = {}
        self.workbook = None
        self.logger = get_logger("excel_processor")
        self._attendance_cache: Optional[pd.DataFrame] = None
        self._travel_cache: Dict[str, pd.DataFrame] = {}
        self._combined_travel_cache: Optional[pd.DataFrame] = None
        
    def load_all_sheets(self, load_workbook_obj: bool = False) -> Dict[str, pd.DataFrame]:
        """
        åŠ è½½æ‰€æœ‰ Sheet æ•°æ®

        Args:
            load_workbook_obj: æ˜¯å¦åŒæ—¶åŠ è½½ openpyxl Workbook å¯¹è±¡ï¼ˆä»…åœ¨éœ€è¦å›å†™æ—¶å¯ç”¨ï¼‰
        """
        try:
            start = time.perf_counter()
            self.logger.info(f"å¼€å§‹è¯»å– Excel æ–‡ä»¶: {self.file_path}")
            all_sheets = pd.read_excel(self.file_path, sheet_name=None)
            elapsed = time.perf_counter() - start

            self.sheets_data = all_sheets
            self._attendance_cache = None
            self._travel_cache = {}
            self._combined_travel_cache = None

            sheet_names = ", ".join(all_sheets.keys())
            self.logger.info(f"Excel è¯»å–å®Œæˆï¼ˆ{sheet_names}ï¼‰ï¼Œè€—æ—¶ {elapsed:.2f}s")
            
            # éƒ¨åˆ†åˆ†æåœºæ™¯ä¸éœ€è¦ Workbookï¼Œä»…åœ¨å›å†™ç­‰åœºæ™¯æŒ‰éœ€åŠ è½½
            if load_workbook_obj:
                wb_start = time.perf_counter()
                self.workbook = load_workbook(self.file_path, keep_links=False)
                self.logger.info(f"openpyxl å·¥ä½œç°¿åŠ è½½å®Œæˆï¼Œè€—æ—¶ {time.perf_counter() - wb_start:.2f}s")
            else:
                self.workbook = None
            
            return self.sheets_data
        except Exception as e:
            raise Exception(f"è¯»å– Excel æ–‡ä»¶å¤±è´¥: {str(e)}")

    def get_sheet_names(self) -> List[str]:
        """
        ä»…è·å– Sheet åç§°ï¼Œé¿å…è¯»å–å…¨éƒ¨æ•°æ®å¯¼è‡´è€—æ—¶
        """
        try:
            workbook = load_workbook(
                self.file_path,
                read_only=True,
                data_only=True,
                keep_links=False
            )
            sheet_names = workbook.sheetnames
            workbook.close()
            return sheet_names
        except Exception as e:
            raise Exception(f"è¯»å– Excel Sheet åç§°å¤±è´¥: {str(e)}")
    
    def get_sheet(self, sheet_name: str) -> Optional[pd.DataFrame]:
        """è·å–æŒ‡å®š Sheet"""
        return self.sheets_data.get(sheet_name)
    
    def clean_attendance_data(self, use_cache: bool = True) -> pd.DataFrame:
        """
        æ¸…æ´—è€ƒå‹¤æ•°æ®ï¼ˆçŠ¶æ€æ˜ç»†ï¼‰
        """
        if use_cache and self._attendance_cache is not None:
            return self._attendance_cache

        df = self.get_sheet("çŠ¶æ€æ˜ç»†")
        if df is None:
            return pd.DataFrame()
        
        # æ ‡å‡†åŒ–åˆ—å
        df = df.copy()
        
        # å¤„ç†æ—¥æœŸæ ¼å¼
        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        
        # å¤„ç†å·¥æ—¶æ•°æ®
        if 'å·¥æ—¶' in df.columns:
            df['å·¥æ—¶'] = pd.to_numeric(df['å·¥æ—¶'], errors='coerce')
        
        # åˆ é™¤ç©ºè¡Œ
        df = df.dropna(subset=['å§“å'], how='all')

        if use_cache:
            self._attendance_cache = df
        
        return df
    
    def clean_travel_data(self, sheet_name: str, use_cache: bool = True) -> pd.DataFrame:
        """
        æ¸…æ´—å·®æ—…æ•°æ®ï¼ˆæœºç¥¨/é…’åº—/ç«è½¦ç¥¨ï¼‰
        """
        if use_cache and sheet_name in self._travel_cache:
            return self._travel_cache[sheet_name]

        df = self.get_sheet(sheet_name)
        if df is None:
            return pd.DataFrame()
        
        df = df.copy()
        
        # å¤„ç†é‡‘é¢å­—æ®µ
        amount_col = 'æˆä¿¡é‡‘é¢' if 'æˆä¿¡é‡‘é¢' in df.columns else 'é‡‘é¢'
        if amount_col in df.columns:
            df[amount_col] = pd.to_numeric(df[amount_col], errors='coerce')
            # å°† NaN å¡«å……ä¸º 0ï¼Œä½†ä¿ç•™æ‰€æœ‰è®°å½•
            df[amount_col] = df[amount_col].fillna(0)
        
        # å¤„ç†æ—¥æœŸå­—æ®µ
        date_cols = ['å‡ºå‘æ—¥æœŸ', 'å…¥ä½æ—¥æœŸ', 'è®¢å•æ—¥æœŸ']
        for col in date_cols:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        
        # ç»Ÿä¸€å·®æ—…äººå‘˜å§“åå­—æ®µ
        if 'å·®æ—…äººå‘˜å§“å' in df.columns:
            df['å§“å'] = df['å·®æ—…äººå‘˜å§“å']
        elif 'é¢„è®¢äººå§“å' in df.columns:
            df['å§“å'] = df['é¢„è®¢äººå§“å']

        if use_cache:
            self._travel_cache[sheet_name] = df
        
        return df

    def _get_combined_travel_df(self) -> pd.DataFrame:
        """
        è·å–å¸¦æ¶ˆè´¹æ—¥æœŸå’Œå·®æ—…ç±»å‹çš„æ±‡æ€»å·®æ—…æ•°æ®ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—ï¼‰
        """
        if self._combined_travel_cache is not None:
            return self._combined_travel_cache

        frames: List[pd.DataFrame] = []
        date_columns = {
            'æœºç¥¨': 'å‡ºå‘æ—¥æœŸ',
            'é…’åº—': 'å…¥ä½æ—¥æœŸ',
            'ç«è½¦ç¥¨': 'å‡ºå‘æ—¥æœŸ'
        }

        for sheet_name, date_col in date_columns.items():
            df = self.clean_travel_data(sheet_name)
            if df.empty or date_col not in df.columns:
                continue

            # ä»…ä¿ç•™éœ€è¦çš„å­—æ®µï¼Œé¿å…å¤åˆ¶æ— å…³æ•°æ®
            temp = df[['å§“å', date_col]].copy()
            temp = temp[temp[date_col].notna()]
            if temp.empty:
                continue

            temp['æ¶ˆè´¹æ—¥æœŸ'] = temp[date_col].dt.date
            temp['å·®æ—…ç±»å‹'] = sheet_name
            frames.append(temp[['å§“å', 'æ¶ˆè´¹æ—¥æœŸ', 'å·®æ—…ç±»å‹']])

        combined = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(
            columns=['å§“å', 'æ¶ˆè´¹æ—¥æœŸ', 'å·®æ—…ç±»å‹']
        )
        self._combined_travel_cache = combined
        return combined
    
    def extract_project_code(self, project_str: str) -> Tuple[str, str]:
        """
        ä»é¡¹ç›®å­—æ®µæå–é¡¹ç›®ä»£ç å’Œåç§°
        æ ¼å¼: "05010013 å¸‚åœº-æ•´æ˜Ÿ..."
        """
        if pd.isna(project_str) or not isinstance(project_str, str):
            return "", ""
        
        # å°è¯•æå–é¡¹ç›®ä»£ç ï¼ˆé€šå¸¸æ˜¯å¼€å¤´çš„æ•°å­—ï¼‰
        match = re.match(r'(\d+)\s+(.*)', project_str.strip())
        if match:
            return match.group(1), match.group(2)
        
        return "", project_str
    
    def aggregate_project_costs(self, top_n: int = 20) -> List[Dict[str, Any]]:
        """
        é¡¹ç›®æˆæœ¬å½’é›†
        
        Args:
            top_n: è¿”å›å‰Nä¸ªé¡¹ç›®ï¼Œå…¶ä½™æ±‡æ€»åˆ°"å…¶ä»–"ï¼ˆé»˜è®¤20ï¼‰
        """
        self.logger.info("=" * 80)
        self.logger.info("å¼€å§‹æ‰§è¡Œé¡¹ç›®æˆæœ¬å½’é›† - è¯¦ç»†æ¨¡å¼ï¼ˆBackendæœåŠ¡ï¼‰")
        self.logger.info("=" * 80)
        
        results = []
        
        # å¤„ç†æ‰€æœ‰å·®æ—…ç›¸å…³çš„ Sheet
        travel_sheets = ['æœºç¥¨', 'é…’åº—', 'ç«è½¦ç¥¨']
        
        all_records = []
        sheet_stats = {}
        
        for sheet_name in travel_sheets:
            self.logger.info(f"\nğŸ“‹ å¤„ç†å·®æ—…è¡¨: {sheet_name}")
            
            # è·å–åŸå§‹æ•°æ®ï¼ˆæœªæ¸…æ´—ï¼‰ä»¥è·å–çœŸå®è¡Œæ•°
            df_raw = self.get_sheet(sheet_name)
            original_count = 0 if df_raw is None else len(df_raw)
            
            df = self.clean_travel_data(sheet_name)
            if df.empty:
                self.logger.warning(f"   âš ï¸  {sheet_name} æ•°æ®ä¸ºç©º")
                continue
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é¡¹ç›®å­—æ®µ
            if 'é¡¹ç›®' not in df.columns:
                self.logger.warning(f"   âš ï¸  {sheet_name} ç¼ºå°‘'é¡¹ç›®'åˆ—")
                continue
            
            amount_col = 'æˆä¿¡é‡‘é¢' if 'æˆä¿¡é‡‘é¢' in df.columns else 'é‡‘é¢'
            self.logger.info(f"   - åŸå§‹è®°å½•æ•°: {original_count}")
            self.logger.info(f"   - æ¸…æ´—åè®°å½•æ•°: {len(df)}")
            self.logger.info(f"   - é‡‘é¢åˆ—: {amount_col}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            record_count = 0
            empty_project_count = 0
            sheet_total_amount = 0
            
            for idx, row in df.iterrows():
                project_str = row.get('é¡¹ç›®', '')
                project_code, project_name = self.extract_project_code(project_str)
                amount = row.get(amount_col, 0)
                
                # ç©ºé¡¹ç›®ä½œä¸ºå•ç‹¬çš„é¡¹ç›®ç±»åˆ«å¤„ç†
                if not project_code:
                    project_code = 'ç©ºé¡¹ç›®'
                    project_name = 'æœªåˆ†é…é¡¹ç›®'
                    empty_project_count += 1
                
                all_records.append({
                    'project_code': project_code,
                    'project_name': project_name,
                    'amount': amount,
                    'type': sheet_name,
                    'person': row.get('å§“å', ''),
                    'date': row.get('å‡ºå‘æ—¥æœŸ', '')
                })
                record_count += 1
                sheet_total_amount += amount
                
                # è¾“å‡ºå‰3æ¡è®°å½•çš„è¯¦ç»†ä¿¡æ¯
                if record_count <= 3:
                    person = row.get('å§“å', 'æœªçŸ¥')
                    date_val = row.get('å‡ºå‘æ—¥æœŸ', '')
                    # å®‰å…¨çš„æ—¥æœŸæ ¼å¼åŒ–
                    if pd.notna(date_val) and hasattr(date_val, 'strftime'):
                        date_str = date_val.strftime('%Y-%m-%d')
                    else:
                        date_str = str(date_val) if pd.notna(date_val) else 'æœªçŸ¥'
                    self.logger.debug(f"      è®°å½•{record_count}: {project_code} | {person} | Â¥{amount:,.2f} | {date_str}")
            
            sheet_stats[sheet_name] = {
                'original_total': original_count,
                'cleaned_total': len(df),
                'record_count': record_count,
                'empty_project_count': empty_project_count,
                'amount': sheet_total_amount
            }
            
            # ç»Ÿè®¡é‡‘é¢åˆ†å¸ƒ - åŸºäºæ‰€æœ‰æ¸…æ´—åè®°å½•
            zero_amount_count = (df[amount_col] == 0).sum() if amount_col in df.columns else 0
            negative_amount_count = (df[amount_col] < 0).sum() if amount_col in df.columns else 0
            positive_amount_count = (df[amount_col] > 0).sum() if amount_col in df.columns else 0
            filtered_count = original_count - len(df)
            
            # è®¡ç®—æ­£æ•°/è´Ÿæ•°é‡‘é¢æ€»å’Œï¼ˆåŸºäºæ‰€æœ‰æ¸…æ´—åè®°å½•ï¼‰
            negative_amount_sum = df[df[amount_col] < 0][amount_col].sum() if amount_col in df.columns and negative_amount_count > 0 else 0
            positive_amount_sum = df[df[amount_col] > 0][amount_col].sum() if amount_col in df.columns and positive_amount_count > 0 else 0
            # æ‰€æœ‰è®°å½•çš„å‡€æ€»é‡‘é¢ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼Œç¡®ä¿ä¸æ­£æ•°+è´Ÿæ•°ä¸€è‡´ï¼‰
            sheet_all_amount = df[amount_col].sum() if amount_col in df.columns else 0
            
            self.logger.info(f"   âœ… å¤„ç†å®Œæˆ:")
            self.logger.info(f"      - æ€»è®°å½•æ•°: {record_count}")
            if empty_project_count > 0:
                self.logger.info(f"      - ç©ºé¡¹ç›®è®°å½•: {empty_project_count} (å·²å½’å…¥\"ç©ºé¡¹ç›®\"ç±»åˆ«)")
            if filtered_count > 0:
                self.logger.warning(f"      âš ï¸  æ•°æ®æ¸…æ´—æ—¶è¿‡æ»¤è®°å½•: {filtered_count}æ¡")
            
            # é‡‘é¢åˆ†å¸ƒç»Ÿè®¡ï¼ˆåŸºäºæ‰€æœ‰æ¸…æ´—åè®°å½•ï¼‰
            self.logger.info(f"      - é‡‘é¢åˆ†å¸ƒï¼ˆå…¨éƒ¨è®°å½•ï¼‰:")
            if positive_amount_count > 0:
                self.logger.info(f"         â€¢ æ­£æ•°é‡‘é¢: {positive_amount_count}æ¡, åˆè®¡ Â¥{positive_amount_sum:,.2f}")
            if negative_amount_count > 0:
                self.logger.warning(f"         â€¢ è´Ÿæ•°é‡‘é¢: {negative_amount_count}æ¡, åˆè®¡ Â¥{negative_amount_sum:,.2f} (é€€æ¬¾/è°ƒæ•´)")
            if zero_amount_count > 0:
                self.logger.info(f"         â€¢ é›¶å€¼é‡‘é¢: {zero_amount_count}æ¡")
            self.logger.info(f"         â€¢ å‡€æ€»é‡‘é¢: Â¥{sheet_all_amount:,.2f}")
        
        # è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
        self.logger.info(f"\nğŸ“Š å·®æ—…æ•°æ®æ±‡æ€»:")
        original_total_records = sum(stats['original_total'] for stats in sheet_stats.values())
        cleaned_total_records = sum(stats['cleaned_total'] for stats in sheet_stats.values())
        total_records = sum(stats['record_count'] for stats in sheet_stats.values())
        empty_project_records = sum(stats['empty_project_count'] for stats in sheet_stats.values())
        total_amount = sum(stats['amount'] for stats in sheet_stats.values())
        
        self.logger.info(f"   - åŸå§‹æ€»è®°å½•æ•°: {original_total_records}")
        self.logger.info(f"   - æ¸…æ´—åæ€»è®°å½•æ•°: {cleaned_total_records}")
        self.logger.info(f"   - å¤„ç†è®°å½•æ•°: {total_records}")
        if empty_project_records > 0:
            self.logger.info(f"   - ç©ºé¡¹ç›®è®°å½•æ•°: {empty_project_records} (å·²å½’å…¥\"ç©ºé¡¹ç›®\"ç±»åˆ«)")
        if original_total_records > cleaned_total_records:
            filtered = original_total_records - cleaned_total_records
            self.logger.warning(f"   âš ï¸  æ•°æ®æ¸…æ´—è¿‡æ»¤äº† {filtered} æ¡è®°å½•ï¼ˆå¯èƒ½æ˜¯æ— æ•ˆæ•°æ®æˆ–åˆ é™¤è¡Œï¼‰")
        self.logger.info(f"   - å‡€æ€»é‡‘é¢: Â¥{total_amount:,.2f}")
        self.logger.info(f"   - ğŸ’¡ è¯´æ˜: è´Ÿæ•°é‡‘é¢ï¼ˆé€€æ¬¾/è°ƒæ•´ï¼‰å·²åŒ…å«åœ¨å‡€æ€»é‡‘é¢è®¡ç®—ä¸­")
        
        # æŒ‰é¡¹ç›®ä»£ç èšåˆ
        if all_records:
            self.logger.info(f"\nğŸ”„ å¼€å§‹èšåˆé¡¹ç›®æ•°æ®...")
            df_projects = pd.DataFrame(all_records)
            self.logger.debug(f"   - å¾…èšåˆè®°å½•æ•°: {len(df_projects)}")
            
            grouped = df_projects.groupby(['project_code', 'project_name']).agg({
                'amount': 'sum',
                'person': 'count'
            }).reset_index()
            
            # æŒ‰æˆæœ¬é™åºæ’åº
            grouped = grouped.sort_values('amount', ascending=False).reset_index(drop=True)
            
            total_count = len(grouped)
            self.logger.info(f"   âœ… èšåˆå®Œæˆï¼Œå…± {total_count} ä¸ªå”¯ä¸€é¡¹ç›®")
            
            # éªŒè¯é‡‘é¢æ€»å’Œ
            grouped_total = grouped['amount'].sum()
            if abs(grouped_total - total_amount) > 0.01:
                self.logger.error(f"   âš ï¸  é‡‘é¢éªŒè¯å¤±è´¥ï¼")
                self.logger.error(f"      åŸå§‹æ€»è®¡: Â¥{total_amount:,.2f}")
                self.logger.error(f"      èšåˆæ€»è®¡: Â¥{grouped_total:,.2f}")
            
            self.logger.info(f"\nğŸ† é¡¹ç›®æˆæœ¬æ’åï¼ˆTop {min(20, total_count)}ï¼‰:")

            # æ—¥å¿—å§‹ç»ˆåªæ˜¾ç¤ºå‰20ä¸ªé¡¹ç›®çš„è¯¦ç»†ä¿¡æ¯ï¼ˆä¿æŒæ—¥å¿—å¯è¯»æ€§ï¼‰
            log_top_n = min(20, total_count)

            # å¦‚æœé¡¹ç›®æ•°é‡è¶…è¿‡ top_nï¼Œå°†è¶…å‡ºéƒ¨åˆ†æ±‡æ€»åˆ°"å…¶ä»–"
            if total_count > top_n:
                self.logger.info(f"   - å±•ç¤ºå‰{top_n}ä¸ªé¡¹ç›®")
                self.logger.info(f"   - å…¶ä½™{total_count - top_n}ä¸ªé¡¹ç›®æ±‡æ€»åˆ°\"å…¶ä»–\"")

                # å‰ top_n ä¸ªé¡¹ç›®ï¼ˆæ·»åŠ åˆ°ç»“æœï¼‰
                for idx, row in grouped.head(top_n).iterrows():
                    project_details = df_projects[
                        df_projects['project_code'] == row['project_code']
                    ].to_dict('records')

                    # è®¡ç®—åˆ†ç±»æˆæœ¬
                    project_df = df_projects[df_projects['project_code'] == row['project_code']]
                    flight_cost = project_df[project_df['type'] == 'æœºç¥¨']['amount'].sum()
                    hotel_cost = project_df[project_df['type'] == 'é…’åº—']['amount'].sum()
                    train_cost = project_df[project_df['type'] == 'ç«è½¦ç¥¨']['amount'].sum()

                    # æ—¥å¿—åªè¾“å‡ºå‰20ä¸ª
                    if idx < log_top_n:
                        self.logger.info(f"\n   #{idx+1}. {row['project_code']} - {row['project_name']}")
                        self.logger.info(f"      æ€»æˆæœ¬: Â¥{row['amount']:,.2f} | è®¢å•æ•°: {int(row['person'])}")
                        self.logger.info(f"      â”œâ”€ æœºç¥¨: Â¥{flight_cost:,.2f}")
                        self.logger.info(f"      â”œâ”€ é…’åº—: Â¥{hotel_cost:,.2f}")
                        self.logger.info(f"      â””â”€ ç«è½¦ç¥¨: Â¥{train_cost:,.2f}")

                    results.append({
                        'project_code': row['project_code'],
                        'project_name': row['project_name'],
                        'total_cost': float(row['amount']),
                        'record_count': int(row['person']),
                        'details': project_details[:10]
                    })
                
                # æ±‡æ€»"å…¶ä»–"é¡¹ç›®
                others_df = grouped.iloc[top_n:]
                others_total_cost = float(others_df['amount'].sum())
                others_record_count = int(others_df['person'].sum())
                
                self.logger.info(f"\n   #{top_n+1}. å…¶ä»–")
                self.logger.info(f"      æ±‡æ€»é¡¹ç›®æ•°: {total_count - top_n}")
                self.logger.info(f"      æ€»æˆæœ¬: Â¥{others_total_cost:,.2f} | è®¢å•æ•°: {others_record_count}")
                
                results.append({
                    'project_code': 'å…¶ä»–',
                    'project_name': f'å…¶ä»–é¡¹ç›®ï¼ˆ{total_count - top_n}ä¸ªï¼‰',
                    'total_cost': others_total_cost,
                    'record_count': others_record_count,
                    'details': []
                })
            else:
                # å¦‚æœä¸è¶…è¿‡ top_nï¼Œè¿”å›å…¨éƒ¨
                self.logger.info(f"   - é¡¹ç›®æ€»æ•°ä¸è¶…è¿‡{top_n}ï¼Œè¿”å›å…¨éƒ¨")
                
                for idx, row in grouped.iterrows():
                    project_details = df_projects[
                        df_projects['project_code'] == row['project_code']
                    ].to_dict('records')
                    
                    # è®¡ç®—åˆ†ç±»æˆæœ¬
                    project_df = df_projects[df_projects['project_code'] == row['project_code']]
                    flight_cost = project_df[project_df['type'] == 'æœºç¥¨']['amount'].sum()
                    hotel_cost = project_df[project_df['type'] == 'é…’åº—']['amount'].sum()
                    train_cost = project_df[project_df['type'] == 'ç«è½¦ç¥¨']['amount'].sum()
                    
                    self.logger.info(f"\n   #{idx+1}. {row['project_code']} - {row['project_name']}")
                    self.logger.info(f"      æ€»æˆæœ¬: Â¥{row['amount']:,.2f} | è®¢å•æ•°: {int(row['person'])}")
                    self.logger.info(f"      â”œâ”€ æœºç¥¨: Â¥{flight_cost:,.2f}")
                    self.logger.info(f"      â”œâ”€ é…’åº—: Â¥{hotel_cost:,.2f}")
                    self.logger.info(f"      â””â”€ ç«è½¦ç¥¨: Â¥{train_cost:,.2f}")
                    
                    results.append({
                        'project_code': row['project_code'],
                        'project_name': row['project_name'],
                        'total_cost': float(row['amount']),
                        'record_count': int(row['person']),
                        'details': project_details[:10]
                    })
            
            # æœ€ç»ˆæ±‡æ€»
            self.logger.info(f"\n" + "=" * 80)
            self.logger.info(f"âœ… é¡¹ç›®æˆæœ¬å½’é›†å®Œæˆ")
            self.logger.info(f"=" * 80)
            self.logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
            self.logger.info(f"   - è¿”å›é¡¹ç›®æ•°: {len(results)}")
            self.logger.info(f"   - æ€»æˆæœ¬: Â¥{sum(r['total_cost'] for r in results):,.2f}")
            self.logger.info(f"   - æ€»è®¢å•æ•°: {sum(r['record_count'] for r in results)}")
            self.logger.info("=" * 80 + "\n")
        else:
            self.logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®è®°å½•")

        return results, total_count
    
    def cross_check_attendance_travel(self) -> List[Dict[str, Any]]:
        """
        äº¤å‰éªŒè¯ï¼šè€ƒå‹¤æ•°æ® vs å·®æ—…æ•°æ®
        """
        anomalies = []
        
        # è·å–è€ƒå‹¤æ•°æ®
        attendance_df = self.clean_attendance_data()
        if attendance_df.empty or 'å½“æ—¥çŠ¶æ€åˆ¤æ–­' not in attendance_df.columns:
            return anomalies
        if 'æ—¥æœŸ' not in attendance_df.columns:
            return anomalies

        # ä»…ä¿ç•™æœ‰æ—¥æœŸçš„æ•°æ®ï¼Œæå‰è®¡ç®—æ—¥æœŸå­—æ®µï¼Œé¿å…åç»­é‡å¤è½¬æ¢
        attendance_df = attendance_df.dropna(subset=['æ—¥æœŸ']).copy()
        if attendance_df.empty:
            return anomalies

        attendance_df['æ—¥æœŸ'] = attendance_df['æ—¥æœŸ'].dt.date
        attendance_df['å½“æ—¥çŠ¶æ€åˆ¤æ–­'] = attendance_df['å½“æ—¥çŠ¶æ€åˆ¤æ–­'].astype(str)
        if 'ä¸€çº§éƒ¨é—¨' in attendance_df.columns:
            attendance_df['ä¸€çº§éƒ¨é—¨'] = attendance_df['ä¸€çº§éƒ¨é—¨'].fillna('æœªçŸ¥éƒ¨é—¨')
        else:
            attendance_df['ä¸€çº§éƒ¨é—¨'] = 'æœªçŸ¥éƒ¨é—¨'

        # åªå…³æ³¨è€ƒå‹¤æ˜¾ç¤ºä¸Šç­çš„è®°å½•ï¼Œç¼©å°è®¡ç®—èŒƒå›´
        work_attendance = attendance_df[
            attendance_df['å½“æ—¥çŠ¶æ€åˆ¤æ–­'].str.contains('ä¸Šç­', na=False)
        ]
        if work_attendance.empty:
            return anomalies

        # èšåˆæ‰€æœ‰å·®æ—…æ•°æ®ï¼ˆå§“å + æ¶ˆè´¹æ—¥æœŸ + å·®æ—…ç±»å‹ï¼‰ï¼Œå¹¶ç¼“å­˜
        travel_df = self._get_combined_travel_df()
        if travel_df.empty:
            return anomalies

        travel_grouped = (
            travel_df.groupby(['å§“å', 'æ¶ˆè´¹æ—¥æœŸ'])['å·®æ—…ç±»å‹']
            .apply(list)
            .reset_index()
            .rename(columns={'æ¶ˆè´¹æ—¥æœŸ': 'æ—¥æœŸ'})
        )

        # åŸºäºå§“å+æ—¥æœŸä¸€æ¬¡æ€§å…³è”ï¼Œé¿å…åŒé‡ for å¾ªç¯
        merged = work_attendance.merge(
            travel_grouped,
            on=['å§“å', 'æ—¥æœŸ'],
            how='inner'
        )

        for _, row in merged.iterrows():
            date_val = row.get('æ—¥æœŸ')
            date_str = date_val.strftime('%Y-%m-%d') if hasattr(date_val, 'strftime') else str(date_val)
            travel_list = row.get('å·®æ—…ç±»å‹', []) or []
            name = row.get('å§“å', '')
            anomalies.append({
                'name': name,
                'date': date_str,
                'department': row.get('ä¸€çº§éƒ¨é—¨', 'æœªçŸ¥éƒ¨é—¨'),
                'anomaly_type': 'A',
                'attendance_status': row.get('å½“æ—¥çŠ¶æ€åˆ¤æ–­', ''),
                'travel_records': travel_list,
                'description': f'{name} åœ¨ {date_str} è€ƒå‹¤æ˜¾ç¤ºä¸Šç­ï¼Œä½†æœ‰ {",".join(travel_list)} æ¶ˆè´¹è®°å½•'
            })

        self.logger.info(f"äº¤å‰éªŒè¯å®Œæˆï¼Œå‘ç° {len(anomalies)} æ¡å¼‚å¸¸è®°å½•")
        return anomalies
    
    def analyze_booking_behavior(self) -> Dict[str, Any]:
        """
        é¢„è®¢è¡Œä¸ºåˆ†æï¼ˆæœºç¥¨ï¼‰
        """
        df = self.clean_travel_data('æœºç¥¨')
        if df.empty or 'æå‰é¢„å®šå¤©æ•°' not in df.columns:
            return {}
        
        # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
        valid_df = df[df['æå‰é¢„å®šå¤©æ•°'].notna() & (df['æå‰é¢„å®šå¤©æ•°'] >= 0)]
        
        if valid_df.empty:
            return {}
        
        amount_col = 'æˆä¿¡é‡‘é¢' if 'æˆä¿¡é‡‘é¢' in valid_df.columns else 'é‡‘é¢'
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_advance = float(valid_df['æå‰é¢„å®šå¤©æ•°'].mean())
        
        # ç›¸å…³æ€§åˆ†æ
        correlation = float(valid_df[['æå‰é¢„å®šå¤©æ•°', amount_col]].corr().iloc[0, 1])
        
        # æå‰å¤©æ•°åˆ†å¸ƒ
        advance_distribution = valid_df['æå‰é¢„å®šå¤©æ•°'].value_counts().to_dict()
        advance_distribution = {str(int(k)): int(v) for k, v in advance_distribution.items()}
        
        # æŒ‰æå‰å¤©æ•°åˆ†ç»„çš„å¹³å‡æˆæœ¬
        cost_by_advance = valid_df.groupby('æå‰é¢„å®šå¤©æ•°')[amount_col].mean().reset_index()
        cost_by_advance_list = [
            {'advance_days': int(row['æå‰é¢„å®šå¤©æ•°']), 'avg_cost': float(row[amount_col])}
            for _, row in cost_by_advance.iterrows()
        ]
        
        return {
            'avg_advance_days': round(avg_advance, 2),
            'correlation_advance_cost': round(correlation, 3),
            'advance_day_distribution': advance_distribution,
            'cost_by_advance_days': sorted(cost_by_advance_list, key=lambda x: x['advance_days'])
        }

    def count_over_standard_orders(self) -> Dict[str, Any]:
        """
        ç»Ÿè®¡å„å·®æ—…ç±»å‹çš„è¶…æ ‡è®¢å•æ•°é‡

        ä¸šåŠ¡è§„åˆ™ï¼š
        - æœºç¥¨ï¼šè¶…æ ‡ç±»å‹åŒ…å«â€œè¶…æŠ˜æ‰£â€æˆ–â€œè¶…æ—¶é—´â€
        - é…’åº—ï¼šæŒ‰â€œæ˜¯å¦è¶…æ ‡â€ä¸ºâ€œæ˜¯â€
        - ç«è½¦ç¥¨ï¼šæŒ‰â€œæ˜¯å¦è¶…æ ‡â€ä¸ºâ€œæ˜¯â€
        """
        flight_df = self.clean_travel_data('æœºç¥¨')
        hotel_df = self.clean_travel_data('é…’åº—')
        train_df = self.clean_travel_data('ç«è½¦ç¥¨')

        def _count_yes(df: pd.DataFrame, column: str) -> int:
            if df.empty or column not in df.columns:
                return 0
            return int(df[df[column].astype(str).str.contains('æ˜¯', na=False)].shape[0])

        def _extract_over_types(value: str) -> List[str]:
            """
            æå–æœºç¥¨çš„è¶…æ ‡ç±»å‹æ ‡ç­¾
            - æ”¯æŒä»¥ç©ºæ ¼ã€é€—å·ã€åˆ†å·ã€æ–œæ ç­‰åˆ†éš”çš„å¤šæ ‡ç­¾æ ¼å¼
            - è‹¥å­—ç¬¦ä¸²ä¸­åŒ…å«å·²çŸ¥å…³é”®å­—ï¼ˆè¶…æŠ˜æ‰£/è¶…æ—¶é—´ï¼‰ä½†æœªåˆ†éš”ï¼Œä¹Ÿèƒ½æ•è·
            """
            if not value or pd.isna(value):
                return []

            raw = str(value)
            tokens = []

            # å¸¸è§åˆ†éš”ç¬¦æ‹†åˆ†
            for part in re.split(r'[;,ï¼Œã€/\\s]+', raw):
                cleaned = part.strip()
                if cleaned and 'è¶…' in cleaned:
                    tokens.append(cleaned)

            # å…œåº•ï¼šå¤„ç†æœªæ˜¾å¼åˆ†éš”ä½†åŒ…å«å…³é”®å­—çš„åœºæ™¯
            for keyword in ['è¶…æŠ˜æ‰£', 'è¶…æ—¶é—´']:
                if keyword in raw and keyword not in tokens:
                    tokens.append(keyword)

            return tokens

        flight_over = 0
        flight_over_type_counter: Counter[str] = Counter()
        if not flight_df.empty:
            if 'è¶…æ ‡ç±»å‹' in flight_df.columns:
                # ç»Ÿè®¡æ•°é‡
                flight_over = int(
                    flight_df[
                        flight_df['è¶…æ ‡ç±»å‹']
                        .astype(str)
                        .str.contains('è¶…æŠ˜æ‰£|è¶…æ—¶é—´', na=False)
                    ].shape[0]
                )

                # ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
                type_series = flight_df['è¶…æ ‡ç±»å‹'].dropna().astype(str)
                for raw_type in type_series:
                    for token in _extract_over_types(raw_type):
                        flight_over_type_counter[token] += 1

                # å¦‚æœæœ‰ç±»å‹åˆ†å¸ƒä½†æœªåŒ¹é…åˆ°æ•°é‡ï¼Œç”¨åˆ†å¸ƒæ±‚å’Œå…œåº•
                if flight_over == 0 and flight_over_type_counter:
                    flight_over = sum(flight_over_type_counter.values())
            elif 'æ˜¯å¦è¶…æ ‡' in flight_df.columns:
                flight_over = _count_yes(flight_df, 'æ˜¯å¦è¶…æ ‡')
                if flight_over > 0:
                    flight_over_type_counter['æœªæ³¨æ˜ç±»å‹'] += flight_over

        hotel_over = _count_yes(hotel_df, 'æ˜¯å¦è¶…æ ‡')
        train_over = _count_yes(train_df, 'æ˜¯å¦è¶…æ ‡')

        total = flight_over + hotel_over + train_over

        return {
            'total': int(total),
            'flight': int(flight_over),
            'hotel': int(hotel_over),
            'train': int(train_over),
            'flight_over_types': {k: int(v) for k, v in flight_over_type_counter.items()},
        }

    def count_total_orders(self) -> Dict[str, int]:
        """
        ç»Ÿè®¡å„å·®æ—…ç±»å‹åŠæ€»è®¢å•æ•°
        """
        flight_df = self.clean_travel_data('æœºç¥¨')
        hotel_df = self.clean_travel_data('é…’åº—')
        train_df = self.clean_travel_data('ç«è½¦ç¥¨')

        flight = 0 if flight_df is None else int(len(flight_df))
        hotel = 0 if hotel_df is None else int(len(hotel_df))
        train = 0 if train_df is None else int(len(train_df))

        return {
            'total': int(flight + hotel + train),
            'flight': flight,
            'hotel': hotel,
            'train': train,
        }
    
    def calculate_department_costs(self, top_n: int = 15) -> List[Dict[str, Any]]:
        """
        éƒ¨é—¨æˆæœ¬æ±‡æ€»ï¼ˆåŒ…å«å¹³å‡å·¥æ—¶å’Œäººæ•°ç»Ÿè®¡ï¼‰
        
        Args:
            top_n: è¿”å›å‰Nä¸ªéƒ¨é—¨ï¼Œå…¶ä½™æ±‡æ€»åˆ°"å…¶ä»–"ï¼ˆé»˜è®¤15ï¼‰
        """
        results = []
        
        # è·å–è€ƒå‹¤æ•°æ®ä»¥è®¡ç®—å·¥æ—¶å’Œäººæ•°
        attendance_df = self.clean_attendance_data()
        dept_attendance_stats = {}
        
        if not attendance_df.empty and 'ä¸€çº§éƒ¨é—¨' in attendance_df.columns:
            # è®¡ç®—æ¯ä¸ªéƒ¨é—¨çš„å¹³å‡å·¥æ—¶å’Œäººæ•°
            for dept in attendance_df['ä¸€çº§éƒ¨é—¨'].unique():
                if pd.isna(dept):
                    continue
                dept_data = attendance_df[attendance_df['ä¸€çº§éƒ¨é—¨'] == dept]
                avg_hours = 0
                if 'å·¥æ—¶' in dept_data.columns:
                    avg_hours = dept_data['å·¥æ—¶'].mean()
                    if pd.isna(avg_hours):
                        avg_hours = 0
                person_count = dept_data['å§“å'].nunique() if 'å§“å' in dept_data.columns else 0
                dept_attendance_stats[dept] = {
                    'avg_hours': float(avg_hours),
                    'person_count': int(person_count)
                }
        
        # å°è¯•ä»å·®æ—…æ±‡æ€» Sheet è·å–
        summary_df = self.get_sheet('å·®æ—…æ±‡æ€»')
        if summary_df is not None and not summary_df.empty:
            if 'ä¸€çº§éƒ¨é—¨' in summary_df.columns and 'æˆæœ¬' in summary_df.columns:
                grouped = summary_df.groupby('ä¸€çº§éƒ¨é—¨').agg({
                    'æˆæœ¬': 'sum'
                }).reset_index()
                
                # æŒ‰æˆæœ¬é™åºæ’åº
                grouped = grouped.sort_values('æˆæœ¬', ascending=False).reset_index(drop=True)
                
                for _, row in grouped.iterrows():
                    dept = row['ä¸€çº§éƒ¨é—¨']
                    stats = dept_attendance_stats.get(dept, {'avg_hours': 0, 'person_count': 0})
                    results.append({
                        'department': dept,
                        'total_cost': float(row['æˆæœ¬']),
                        'flight_cost': 0,
                        'hotel_cost': 0,
                        'train_cost': 0,
                        'avg_hours': stats['avg_hours'],
                        'person_count': stats['person_count']
                    })
                
                # åº”ç”¨ top_n é™åˆ¶å¹¶æ·»åŠ "å…¶ä»–"
                return self._apply_top_n_with_others(results, top_n, 'department')
        
        # å¦‚æœæ²¡æœ‰æ±‡æ€»è¡¨ï¼Œä»æ˜ç»†è®¡ç®—
        travel_data = {
            'æœºç¥¨': 'flight_cost',
            'é…’åº—': 'hotel_cost',
            'ç«è½¦ç¥¨': 'train_cost'
        }
        
        dept_costs = {}
        
        for sheet_name, cost_key in travel_data.items():
            df = self.clean_travel_data(sheet_name)
            if df.empty:
                continue
            
            # å°è¯•å…³è”éƒ¨é—¨ä¿¡æ¯
            if not attendance_df.empty and 'ä¸€çº§éƒ¨é—¨' in attendance_df.columns:
                # Merge with attendance to get department
                name_dept = attendance_df[['å§“å', 'ä¸€çº§éƒ¨é—¨']].drop_duplicates()
                df = df.merge(name_dept, on='å§“å', how='left')
            
            if 'ä¸€çº§éƒ¨é—¨' not in df.columns:
                continue
            
            amount_col = 'æˆä¿¡é‡‘é¢' if 'æˆä¿¡é‡‘é¢' in df.columns else 'é‡‘é¢'
            
            for _, row in df.iterrows():
                dept = row.get('ä¸€çº§éƒ¨é—¨', 'æœªçŸ¥éƒ¨é—¨')
                if pd.isna(dept):
                    dept = 'æœªçŸ¥éƒ¨é—¨'
                
                if dept not in dept_costs:
                    stats = dept_attendance_stats.get(dept, {'avg_hours': 0, 'person_count': 0})
                    dept_costs[dept] = {
                        'department': dept,
                        'total_cost': 0,
                        'flight_cost': 0,
                        'hotel_cost': 0,
                        'train_cost': 0,
                        'avg_hours': stats['avg_hours'],
                        'person_count': stats['person_count']
                    }
                
                amount = row.get(amount_col, 0) or 0
                dept_costs[dept][cost_key] += amount
                dept_costs[dept]['total_cost'] += amount
        
        results = list(dept_costs.values())
        results = sorted(results, key=lambda x: x['total_cost'], reverse=True)
        
        # åº”ç”¨ top_n é™åˆ¶å¹¶æ·»åŠ "å…¶ä»–"
        return self._apply_top_n_with_others(results, top_n, 'department')
    
    def _apply_top_n_with_others(self, results: List[Dict[str, Any]], top_n: int, name_key: str) -> List[Dict[str, Any]]:
        """
        åº”ç”¨ Top N é™åˆ¶ï¼Œå°†è¶…å‡ºéƒ¨åˆ†æ±‡æ€»åˆ°"å…¶ä»–"
        
        Args:
            results: å·²æ’åºçš„ç»“æœåˆ—è¡¨
            top_n: ä¿ç•™çš„å‰Næ¡è®°å½•
            name_key: åç§°å­—æ®µï¼ˆ'department' æˆ– 'project_code'ï¼‰
        
        Returns:
            å¤„ç†åçš„ç»“æœåˆ—è¡¨
        """
        if not results or len(results) <= top_n:
            return results
        
        # å‰ top_n æ¡
        top_results = results[:top_n]
        
        # å‰©ä½™çš„æ±‡æ€»åˆ°"å…¶ä»–"
        others = results[top_n:]
        total_count = len(results)
        
        others_summary = {
            name_key: 'å…¶ä»–',
            'total_cost': sum(item.get('total_cost', 0) for item in others),
            'flight_cost': sum(item.get('flight_cost', 0) for item in others),
            'hotel_cost': sum(item.get('hotel_cost', 0) for item in others),
            'train_cost': sum(item.get('train_cost', 0) for item in others),
        }
        
        # å¦‚æœæ˜¯éƒ¨é—¨æ•°æ®ï¼Œè®¡ç®—å¹³å‡å·¥æ—¶å’Œæ€»äººæ•°
        if name_key == 'department':
            avg_hours_list = [item.get('avg_hours', 0) for item in others if item.get('avg_hours', 0) > 0]
            others_summary['avg_hours'] = sum(avg_hours_list) / len(avg_hours_list) if avg_hours_list else 0
            others_summary['person_count'] = sum(item.get('person_count', 0) for item in others)
        
        # å¦‚æœæ˜¯é¡¹ç›®æ•°æ®
        if name_key == 'project_code':
            others_summary['project_name'] = f'å…¶ä»–é¡¹ç›®ï¼ˆ{total_count - top_n}ä¸ªï¼‰'
            others_summary['record_count'] = sum(item.get('record_count', 0) for item in others)
            others_summary['details'] = []
        
        top_results.append(others_summary)
        
        return top_results
    
    def get_attendance_summary(self) -> Dict[str, Any]:
        """
        è€ƒå‹¤æ•°æ®æ±‡æ€»
        """
        df = self.clean_attendance_data()
        if df.empty:
            return {}
        
        total_records = len(df)
        total_persons = df['å§“å'].nunique() if 'å§“å' in df.columns else 0
        
        status_distribution = {}
        if 'å½“æ—¥çŠ¶æ€åˆ¤æ–­' in df.columns:
            status_distribution = df['å½“æ—¥çŠ¶æ€åˆ¤æ–­'].value_counts().to_dict()
        
        avg_work_hours = 0
        if 'å·¥æ—¶' in df.columns:
            avg_work_hours = float(df['å·¥æ—¶'].mean())
        
        return {
            'total_records': total_records,
            'total_persons': total_persons,
            'status_distribution': status_distribution,
            'avg_work_hours': round(avg_work_hours, 2)
        }
    
    def write_analysis_results(self, results: Dict[str, Any], output_path: Optional[str] = None) -> str:
        """
        å°†åˆ†æç»“æœå›å†™åˆ° Excelï¼ˆæ–°å¢ Sheetï¼‰
        ä½¿ç”¨ openpyxl ä¿ç•™åŸæ ¼å¼
        """
        if output_path is None:
            base_name = os.path.splitext(self.file_path)[0]
            output_path = f"{base_name}_analyzed.xlsx"
        
        if self.workbook is None:
            self.workbook = load_workbook(self.file_path)
        
        # åˆ›å»ºåˆ†æç»“æœ Sheet
        sheet_name = "åˆ†æç»“æœ"
        if sheet_name in self.workbook.sheetnames:
            del self.workbook[sheet_name]
        
        ws = self.workbook.create_sheet(sheet_name)
        
        # å†™å…¥æ ‡é¢˜
        ws.append(["CorpPilot æ•°æ®åˆ†ææŠ¥å‘Š"])
        ws.append([f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"])
        ws.append([])
        
        # å†™å…¥é¡¹ç›®æˆæœ¬
        if 'project_costs' in results and results['project_costs']:
            ws.append(["é¡¹ç›®æˆæœ¬å½’é›†"])
            ws.append(["é¡¹ç›®ä»£ç ", "é¡¹ç›®åç§°", "æ€»æˆæœ¬", "è®°å½•æ•°"])
            for item in results['project_costs']:
                ws.append([
                    item['project_code'],
                    item['project_name'],
                    item['total_cost'],
                    item['record_count']
                ])
            ws.append([])
        
        # å†™å…¥éƒ¨é—¨æˆæœ¬
        if 'department_costs' in results and results['department_costs']:
            ws.append(["éƒ¨é—¨æˆæœ¬æ±‡æ€»"])
            ws.append(["éƒ¨é—¨", "æ€»æˆæœ¬", "æœºç¥¨", "é…’åº—", "ç«è½¦ç¥¨"])
            for item in results['department_costs']:
                ws.append([
                    item['department'],
                    item['total_cost'],
                    item['flight_cost'],
                    item['hotel_cost'],
                    item['train_cost']
                ])
            ws.append([])
        
        # å†™å…¥å¼‚å¸¸è®°å½•
        if 'anomalies' in results and results['anomalies']:
            ws.append(["äº¤å‰éªŒè¯å¼‚å¸¸"])
            ws.append(["å§“å", "æ—¥æœŸ", "å¼‚å¸¸ç±»å‹", "è€ƒå‹¤çŠ¶æ€", "è¯´æ˜"])
            for item in results['anomalies']:
                ws.append([
                    item['name'],
                    item['date'],
                    item['anomaly_type'],
                    item['attendance_status'],
                    item['description']
                ])
        
        # ä¿å­˜æ–‡ä»¶
        self.workbook.save(output_path)
        
        return output_path
